# General settings for Hugging Face libraries
HF_HUB_DISABLE_TELEMETRY=1
HF_HUB_DISABLE_IMPLICIT_TOKEN=1
HF_HUB_DISABLE_XET=1 # disable downloading via XET protocol, as clearing XET cache needs to be done manually

# Hugging Face token required to access gated models
HF_TOKEN=

# Optionally set custom cache directory to store models (if not set standard HF directory will be used, usually ~/.cache/huggingface)
# HF_HOME=

# Preprocess settings
DOWNLOAD_URL=https://raw.githubusercontent.com/rstodden/DEPlain/refs/heads/main/E__Sentence-level_Corpus/DEplain-web-sent/manual/open/test.csv # If not set, will try to read data from data/data.csv
SOURCES_COLUMN_NAME=original # If not set, will try to read from column 'source'
REFERENCES_COLUMN_NAME=simplification # If not set, will try to read from column 'reference'

# Custom inference settings
# USE_CPU=True # If not set (or False), GPU inference will be used
# NUM_THREADS=10 # If not set, llama-cpp will automatically assign
# STRUCTURED_OUTPUT_KEY=mykey # If not set, 'result' will be used
# TEMPERATURE=0.1 # If not set, 0.2 will be used (llama-cpp default)
CONTEXT_LENGTH=512 # If not set, 0 will be used (uses context window defined by model)
