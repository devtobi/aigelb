# General settings for Hugging Face libraries
HF_HUB_DISABLE_TELEMETRY=1
HF_HUB_DISABLE_IMPLICIT_TOKEN=1
HF_HUB_DISABLE_XET=1 # disable downloading via XET protocol, as clearing XET cache needs to be done manually

# Hugging Face token required to access gated models
HF_TOKEN=

# Custom cache directory to store models (if not set standard HF directory will be used, usually ~/.cache/huggingface)
HF_HOME=./.cache

# Preprocess settings
DOWNLOAD_URL=https://raw.githubusercontent.com/M4XMU3/d2e/refs/heads/main/01_preparations/parallel-corpora.csv # If not set, will try to read data from data/data.csv
SOURCES_COLUMN_NAME="Normal Language" # If not set, will try to read from column 'source'
REFERENCES_COLUMN_NAME="Easy Language" # If not set, will try to read from column 'reference'
COLUMN_SEPARATOR=; # If not set, will use ',' as default

# Custom inference settings
# USE_CPU=True # If not set (or False), GPU inference will be used
# NUM_THREADS=10 # If not set, llama-cpp will automatically assign
# STRUCTURED_OUTPUT_KEY=mykey # If not set, 'result' will be used
# TEMPERATURE=0.1 # If not set, 0.2 will be used (llama-cpp default)
MAX_CONTEXT_LENGTH=5120 # If not set, uses individual content length from models.csv, if not set tries to load model size from model metadata
